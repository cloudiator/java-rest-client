/*
 * Cloudiator REST Api
 * No description provided (generated by Swagger Codegen https://github.com/swagger-api/swagger-codegen)
 *
 * OpenAPI spec version: 0.2.0
 * Contact: daniel.baur@uni-ulm.de
 *
 * NOTE: This class is auto generated by the swagger code generator program.
 * https://github.com/swagger-api/swagger-codegen.git
 * Do not edit the class manually.
 */


package io.github.cloudiator.rest.model;

import java.util.Objects;
import com.google.gson.TypeAdapter;
import com.google.gson.annotations.JsonAdapter;
import com.google.gson.annotations.SerializedName;
import com.google.gson.stream.JsonReader;
import com.google.gson.stream.JsonWriter;
import io.github.cloudiator.rest.model.TaskInterface;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.io.Serializable;

/**
 * Subtype of TaskInterface. Describes how to deploy a Task to Spark. 
 */
@ApiModel(description = "Subtype of TaskInterface. Describes how to deploy a Task to Spark. ")

public class SparkInterface extends TaskInterface implements Serializable {
  private static final long serialVersionUID = 1L;

  @SerializedName("file")
  private String file = null;

  @SerializedName("className")
  private String className = null;

  @SerializedName("arguments")
  private List<String> arguments = null;

  @SerializedName("sparkArguments")
  private java.util.Map sparkArguments = null;

  @SerializedName("sparkConfiguration")
  private java.util.Map sparkConfiguration = null;

  /**
   * Gets or Sets processMapping
   */
  @JsonAdapter(ProcessMappingEnum.Adapter.class)
  public enum ProcessMappingEnum {
    SINGLE("SINGLE"),
    
    CLUSTER("CLUSTER");

    private String value;

    ProcessMappingEnum(String value) {
      this.value = value;
    }

    public String getValue() {
      return value;
    }

    @Override
    public String toString() {
      return String.valueOf(value);
    }

    public static ProcessMappingEnum fromValue(String text) {
      for (ProcessMappingEnum b : ProcessMappingEnum.values()) {
        if (String.valueOf(b.value).equals(text)) {
          return b;
        }
      }
      return null;
    }

    public static class Adapter extends TypeAdapter<ProcessMappingEnum> {
      @Override
      public void write(final JsonWriter jsonWriter, final ProcessMappingEnum enumeration) throws IOException {
        jsonWriter.value(enumeration.getValue());
      }

      @Override
      public ProcessMappingEnum read(final JsonReader jsonReader) throws IOException {
        String value = jsonReader.nextString();
        return ProcessMappingEnum.fromValue(String.valueOf(value));
      }
    }
  }

  @SerializedName("processMapping")
  private ProcessMappingEnum processMapping = null;

  public SparkInterface file(String file) {
    this.file = file;
    return this;
  }

   /**
   * An URI where the executable of the Spark Application can be retrieved. Either a URL pointing to a web endpoint, or a locally available file. 
   * @return file
  **/
  @ApiModelProperty(value = "An URI where the executable of the Spark Application can be retrieved. Either a URL pointing to a web endpoint, or a locally available file. ")
  public String getFile() {
    return file;
  }

  public void setFile(String file) {
    this.file = file;
  }

  public SparkInterface className(String className) {
    this.className = className;
    return this;
  }

   /**
   * Optional className of the class containing the main method. Only required for Java. 
   * @return className
  **/
  @ApiModelProperty(value = "Optional className of the class containing the main method. Only required for Java. ")
  public String getClassName() {
    return className;
  }

  public void setClassName(String className) {
    this.className = className;
  }

  public SparkInterface arguments(List<String> arguments) {
    this.arguments = arguments;
    return this;
  }

  public SparkInterface addArgumentsItem(String argumentsItem) {
    if (this.arguments == null) {
      this.arguments = new ArrayList<String>();
    }
    this.arguments.add(argumentsItem);
    return this;
  }

   /**
   * Array of arguments passed to the application. 
   * @return arguments
  **/
  @ApiModelProperty(value = "Array of arguments passed to the application. ")
  public List<String> getArguments() {
    return arguments;
  }

  public void setArguments(List<String> arguments) {
    this.arguments = arguments;
  }

  public SparkInterface sparkArguments(java.util.Map sparkArguments) {
    this.sparkArguments = sparkArguments;
    return this;
  }

   /**
   * Additional Arguments passed to Spark. 
   * @return sparkArguments
  **/
  @ApiModelProperty(value = "Additional Arguments passed to Spark. ")
  public java.util.Map getSparkArguments() {
    return sparkArguments;
  }

  public void setSparkArguments(java.util.Map sparkArguments) {
    this.sparkArguments = sparkArguments;
  }

  public SparkInterface sparkConfiguration(java.util.Map sparkConfiguration) {
    this.sparkConfiguration = sparkConfiguration;
    return this;
  }

   /**
   * Spark configuration properties. 
   * @return sparkConfiguration
  **/
  @ApiModelProperty(value = "Spark configuration properties. ")
  public java.util.Map getSparkConfiguration() {
    return sparkConfiguration;
  }

  public void setSparkConfiguration(java.util.Map sparkConfiguration) {
    this.sparkConfiguration = sparkConfiguration;
  }

  public SparkInterface processMapping(ProcessMappingEnum processMapping) {
    this.processMapping = processMapping;
    return this;
  }

   /**
   * Get processMapping
   * @return processMapping
  **/
  @ApiModelProperty(value = "")
  public ProcessMappingEnum getProcessMapping() {
    return processMapping;
  }

  public void setProcessMapping(ProcessMappingEnum processMapping) {
    this.processMapping = processMapping;
  }


  @Override
  public boolean equals(java.lang.Object o) {
    if (this == o) {
      return true;
    }
    if (o == null || getClass() != o.getClass()) {
      return false;
    }
    SparkInterface sparkInterface = (SparkInterface) o;
    return Objects.equals(this.file, sparkInterface.file) &&
        Objects.equals(this.className, sparkInterface.className) &&
        Objects.equals(this.arguments, sparkInterface.arguments) &&
        Objects.equals(this.sparkArguments, sparkInterface.sparkArguments) &&
        Objects.equals(this.sparkConfiguration, sparkInterface.sparkConfiguration) &&
        Objects.equals(this.processMapping, sparkInterface.processMapping) &&
        super.equals(o);
  }

  @Override
  public int hashCode() {
    return Objects.hash(file, className, arguments, sparkArguments, sparkConfiguration, processMapping, super.hashCode());
  }


  @Override
  public String toString() {
    StringBuilder sb = new StringBuilder();
    sb.append("class SparkInterface {\n");
    sb.append("    ").append(toIndentedString(super.toString())).append("\n");
    sb.append("    file: ").append(toIndentedString(file)).append("\n");
    sb.append("    className: ").append(toIndentedString(className)).append("\n");
    sb.append("    arguments: ").append(toIndentedString(arguments)).append("\n");
    sb.append("    sparkArguments: ").append(toIndentedString(sparkArguments)).append("\n");
    sb.append("    sparkConfiguration: ").append(toIndentedString(sparkConfiguration)).append("\n");
    sb.append("    processMapping: ").append(toIndentedString(processMapping)).append("\n");
    sb.append("}");
    return sb.toString();
  }

  /**
   * Convert the given object to string with each line indented by 4 spaces
   * (except the first line).
   */
  private String toIndentedString(java.lang.Object o) {
    if (o == null) {
      return "null";
    }
    return o.toString().replace("\n", "\n    ");
  }

}

